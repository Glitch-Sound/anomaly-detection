[MODEL]
learning_rate = 0.001
batch_size = 4
num_epochs = 10
input_size = 384
flow_steps = 16
hidden_ratio = 1.2
conv3x3_only = false
backbone = deit_base_distilled_patch16_384
vit_layers = 9,12
lr_scheduler_factor = 0.5
lr_scheduler_patience = 3
lr_scheduler_min_lr = 0.000001
lr_scheduler_monitor = train_loss

[THRESHOLD]
epsilon = 0.0001

[INFER]
score_pooling = max
score_q = 0.999

[DATA]
train_data_path = data/train/good/
test_data_path = data/test/
val_split_ratio = 0.1
num_workers = 2

[OUTPUT]
model_save_path = params/model.pth

[RESULT]
output_dir = result

[HEATMAP]
activation_percentile = 0.7
activation_min_value = 0.5
blur_kernel_size = 5
blur_sigma = 1.0
normalize_clip_percentile = 0.99
normalize_clip_lower_percentile = 0.0
resize_to_input_size = true
